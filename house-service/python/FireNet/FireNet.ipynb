{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JT1d8k3TTBn3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "categories = {'no_fire': 0, 'fire': 1}\n",
        "\n",
        "IMG_SIZE = 224\n",
        "VIDEO_DIR = 'videos/'\n",
        "\n",
        "def extract_frames_from_video(video_path):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_resized = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
        "        frames.append(frame_resized)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def create_training_data():\n",
        "    training_data = []\n",
        "    for category in os.listdir(VIDEO_DIR):\n",
        "        if category.startswith('.'):\n",
        "            continue\n",
        "        print(category)\n",
        "        category_path = os.path.join(VIDEO_DIR, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            for video_file in tqdm(os.listdir(category_path)):\n",
        "                if video_file.endswith('.mp4'):\n",
        "                    video_path = os.path.join(category_path, video_file)\n",
        "                    frames = extract_frames_from_video(video_path)\n",
        "                    for frame in frames:\n",
        "                        frame_tensor = torch.from_numpy(frame.transpose((2, 0, 1))).float()\n",
        "                        training_data.append([frame_tensor, categories[category]])\n",
        "    return training_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = create_training_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8jYhEb5RFIG",
        "outputId": "223de959-62b8-40cf-e023-2794e7767681"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fire\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_fire\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:24<00:00, 24.56s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.stack([sample[0] for sample in training_data])\n",
        "y = torch.Tensor([label for _, label in training_data])"
      ],
      "metadata": {
        "id": "uD44qtiLnYRD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = torch.split(X, int(0.8 * len(X)), dim=0)\n",
        "y_train, y_test = torch.split(y, int(0.8 * len(y)), dim=0)"
      ],
      "metadata": {
        "id": "XnkZyLk_tUfF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "LwvR8-d2t7v2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, inplanes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.apply_proj = stride != 1 or inplanes != planes\n",
        "        if self.apply_proj:\n",
        "            self.proj = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
        "            self.proj_bn = nn.BatchNorm2d(planes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        f = self.bn2(self.conv2(F.relu(self.bn1(self.conv1(X)))))\n",
        "\n",
        "        if self.apply_proj:\n",
        "            g = self.proj_bn(self.proj(X))\n",
        "        else:\n",
        "            g = X\n",
        "        return F.relu(f + g)\n",
        "\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.resnet = nn.Sequential(\n",
        "            ResidualBlock(3, 16, stride=2),\n",
        "            ResidualBlock(16, 32, stride=2),\n",
        "            ResidualBlock(32, 64, stride=2)\n",
        "        )\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "model = BinaryClassifier()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.unsqueeze(1))  # Unsqueeze per adattare la forma delle etichette\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs >= 0.5).squeeze().float()  # Considera 1 se l'output è >= 0.5, altrimenti 0\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIz3QDcuTn1a",
        "outputId": "cec2dbae-87cd-4bd4-c209-00b8a5e3771b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 10.890434834361077\n",
            "Epoch [2/10], Loss: 11.40625\n",
            "Epoch [3/10], Loss: 11.40625\n",
            "Epoch [4/10], Loss: 11.40625\n",
            "Epoch [5/10], Loss: 11.40625\n",
            "Epoch [6/10], Loss: 11.40625\n",
            "Epoch [7/10], Loss: 11.40625\n",
            "Epoch [8/10], Loss: 11.40625\n",
            "Epoch [9/10], Loss: 11.40625\n",
            "Epoch [10/10], Loss: 11.40625\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 64 * 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.argmax(-1).float(), labels)  # Convert labels to float and unsqueeze\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs >= 0.5).squeeze().float()  # Consider 1 if the output is >= 0.5, else 0\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "QVcMnqNyuCGJ",
        "outputId": "5472aae6-f93f-4095-dec5-f833212c03fa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-59be538c4700>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert labels to float and unsqueeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "X = X/255.0\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "1d98SZ-gabdI"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=X.shape[1:]))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=2, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X, y, batch_size=32, epochs=3,validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dau5T3rAiLZR",
        "outputId": "72f42f20-1db4-4a24-f476-e6055be14af3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "35/35 [==============================] - 68s 2s/step - loss: 0.1611 - accuracy: 0.9679 - val_loss: 4.4363e-08 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "35/35 [==============================] - 66s 2s/step - loss: 3.3152e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "35/35 [==============================] - 67s 2s/step - loss: 4.0105e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('videos/test.jpg')\n",
        "img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "img = img.astype('float32') / 255.0\n",
        "\n",
        "fire = tf.convert_to_tensor(img[np.newaxis, ...])\n",
        "\n",
        "predictions = model.predict(fire)\n",
        "np.argmax(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9HID5gfignk",
        "outputId": "23f9bbd3-8678-4169-83af-609f32c9888e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('videos/test2.jpg')\n",
        "img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "img = img.astype('float32') / 255.0\n",
        "\n",
        "non_fire = tf.convert_to_tensor(img[np.newaxis, ...])\n",
        "\n",
        "predictions = model.predict(non_fire)\n",
        "np.argmax(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkBxF2mZmI9b",
        "outputId": "09828e35-1ef2-455a-9860-7a75ab30a74e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.load_model('TrainedModels/Fire-64x64-color-v7-soft.h5')"
      ],
      "metadata": {
        "id": "lkj9K2nP8X75"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}